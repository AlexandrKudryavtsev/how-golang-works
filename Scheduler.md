# Планировщик

___Планировщик (scheduler) Go___ - это механизм `runtime`, который управляет горутинами. В статье `runtime` планировщик уже частично обсуждался, однако в этой статье он будет рассмотрен более детально.

### Планировщики ОС

Планировщик Go работает в связке с планировщиком ОС, но предоставляет более высокоуровневую абстракцию для конкурентного выполнения кода.

Для понимания работы планировщика Go потребуются два основных понятия:

1) ***Процесс*** -  выполняющаяся программа.
2) ***Поток (thread)*** - обособленная часть процесса, которая может выполняться на CPU. У каждого процесса есть один главный тред и по мере необходимости вспомогательные.

Это существенное упрощение, в Windows и Linux это все реализовано сложнее.

У компьютера есть ядра CPU, которые выполняют вычисления. В зависимости от их количества возможны два подхода:

1) ***Конкурентность (Concurrency)***
    - Если ядро одно, потоки выполняются по очереди, получая небольшие кванты времени.
    - Для пользователя это выглядит как одновременная работа, хотя на самом деле потоки быстро переключаются.
2) ***Параллелизм (Parallelism)***
    - Если ядер много, потоки могут выполняться действительно одновременно, по одному на каждое ядро.

Эти подходы сочетаются: обычно потоков больше, чем ядер, поэтому ОС комбинирует параллельное и конкурентное выполнение.

Но у потоков ОС есть недостаток: их переключение ***context switching*** требует значительных ресурсов, если же потоков будет слишком большое количество, то процессор будет только успевать между ними переключаться. Кроме того, каждый поток занимает как правило, существенное количество памяти.

В идеале, программа должна создавать как можно меньше тредов. Go решает эту проблему, вводя ***легковесные горутины***, которыми управляет его собственный планировщик.

### GMP модель

Каждый вызов функции через `go` запускает её в отдельном "потоке", что позволяет выполняться ей конкурентно с другим кодом. Тогда это выполнение этой функции будет конкурировать с выполнением "основного" кода и другими функциями, запущенными при помощи `go`.

Назовем все такие "потоки" ***горутинами*** - это легковесные аналоги потоков (threads), но управляемые рантаймом Go, а не ОС. Притом, в конечном счете горутины будут исполняться в треде.

> Еще говорят, горутины и Go-планировщик - это user space, а треды и планировщик ОС - это kernel space.

Каждая горутина может быть в одном из этих статусах:

- ***Waiting*** — не готова к запуску, так как чего-то ждёт.
- ***Runnable*** — готова к запуску, как только освободится тред.
- ***Executing*** - выполняется на каком-то треде.

У треда статусы аналогичные.

***Машина M (machine)*** будет непосредственно выполнять горутину. По сути, машиной является системный тред. ***Процессор P (processor)*** будет перекладывать горутины в машины, то есть привязывать горутину к треду.

> Процессор P - это не ядро CPU. Термины просто похожи названиями.

Машины M, процессоры P и горутины G составляют ___GMP модель___. 

### Пул тредов

По мере появления и выполнения горутин нужно создавать треды. Очевидно, что создавать каждой горутине новый тред - это плохое решение. Пусть после выполнения горутины процессор перемещает использованный тред в ***пул тредов***. 

Тогда теперь при запуске горутины:

1) Проверяем, есть ли в пуле свободный тред. Если есть, берём его для выполнения горутины.

2) Если нет, проверяем сколько сейчас задействовано тредов. Если меньше установленного лимита, то создаём новый тред и отдаём ему горутину. Когда горутина закончит работу, отправим этот тред в пул.

3) Если же количество тредов достигло лимита, горутина будет ждать пока какой-нибудь из ранее созданных не освободится, вернувшись в пул. Как освободится, передадим ему горутину в работу.

Теперь появилась очередь из ждущих горутин - ***Global Run Queue (GRQ)***. GRQ - это FIFO очередь (first in, first out), чем раньше горутина пришла, тем раньше получит тред.

Лимит тредов равен количеству доступных ядер CPU. Тредов не должно быть больше, чем ядер CPU. Теперь можно позволить к Треду приставить по отдельному Процессору. То есть, у каждого Процессора теперь будет свой собственный тред.

### Локальные очереди и Work Stealing

Введение GPQ привело к новой проблеме. Теперь при параллельном доступе нескольких процессоров к GPQ, может возникнуть ***состояние гонки (race condition)***. Для избежания этого доступ GPQ осуществляется при помощи Mutex.

Теперь проблемы с доступом к GRQ не будет, но он стал напорядок медленнее, особенно эта проблема актуальна для компьютеров с большим количеством ядер CPU.

Добавим каждому Процессору свою ***локальную очередь LRQ (local run queue)***, чтобы он брал задачи и оттуда тоже. Но как же будут попадать горутины в LRQ? Каждый раз, когда Процессор пытается взять какую-то горутину, он будет действовать по этому алгоритму:

1) 1/61 раз проверяем GRQ, и если там есть горутины, то берём оттуда.
2) Если нет, проверяем LRQ.
3) Если там нет, пытаемся украсть у другого Процессора.
4) Если не получилось, проверяем GRQ.
5) Network Poller (будет объяснено позже)

На этапе 3 происходит ***Work Stealing***. Когда Процессор простаивает, он забирает горутины из LRQ других Процессоров.

### Handoff и Network Poller

Теперь решим еще одну проблему: когда горутина выполнит какую-то блокирующую операцию, чаще всего это какой-то syscall, то будет заблокирован весь тред и ядро CPU будет простаивать. Если же в LRQ будут runnable горутины, то они будут ждать. В качестве оптимизации можно отвязать тред от процессора. Этот механизм называется ***handoff***.

Однако горутины могут совершать очень много syscall-ов за раз. Такой механизм будет порождать много тредов. Притом, некоторые syscall блокируют тред на короткое время.

Давайте введем новый процесс ***sysmon***, который будет в фоновом режиме:

1) Если syscall заблокирует тред надолго, то выполнит handoff.
2) Иначе позволит треду недолго быть заблокированным в течение 10 миллисекунд. По окончанию таймаута будет handoff.

По окончанию syscall, горутина вернется к изначальному процессору, если он будет занят, то она попадет в GRQ.

Блокировка треда при syscall неизбежна. Благо что сами ОС предлагают обход - механизмы для выполнения асинхронных системных вызовов: epoll (Linux), kqueue (MacOS, BSD), IOCP (Windows). Как правило, они используются для работы с сетью.

Теперь тред инициирует syscall и идёт по другим своим делам. Системный вызов будет зарегистрирован в специальной системе. Проверять же статус syscall-ов в специальных системах будет ***Network Poller (netpoller)***.

Итого: если горутина собирается выполнить syscall, который может выполняться асинхронно, вместо блокировки треда:

1) Операция регистрируется в Network Poller
2) Сама горутина переводится в состояние Waiting и передается Netpoller'у.
3) Процессор освобождается для выполнения других горутин

Вспомним алгоритм из пункта "Локальные очереди и Work Stealing". Процессор будет иногда проверять и netpoller и горутины, syscall которых завершился, снова попадают на исполнение. Кроме того, sysmon будет сам периодически проверять netpoller и перекидывать горутины в GRQ.

> Не все sycall-ы могут выполняться асинхронно. В основном в Netpoller будут попадать syscall, занятые работой с сетью. А syscall, например, по чтению из файла не может выполниться асинхронно и в Netpoller не попадет.

### Вытеснение "жадных" горутин.

Процессоры выполняют горутины из локальной очереди (LRQ) последовательно. Если горутины долгоживущие (например, фоновые задачи), они могут занять весь процессор, блокируя выполнение других горутин.

Для решения этого в Go была внедрен ***кооперативная многозадачность***. В этом подходе горутины ***добровольно уступают*** процессор в безопасных точках:

1) Перед вызовом функции (пролог): создаётся фрейм стека, данные сохранены — прерывание безопасно.
2) При блокирующих операциях (syscall, таймеры): горутина всё равно ждёт, можно переключиться на другую.

Sysmon проверяет время выполнения горутин. Если горутина работает >10 мс, sysmon выставляет горутине флаг `stackPreempt=stackguard`. При последующей проверке горутина увидит этот флаг и передаст тред планировщику.

Однако, если горутина не делает блокирующих операций и не вызывает функции, то sysmon не сможет ее остановить впринципе. Для этого добавили ***принудительное вытеснение***. При помощи сигналов ОС, sysmon передает информацию горутине и та передает тред планировщику.

Горутины чаще добровольно уступают, однако у sysmon всегда есть запасной вариант с принудительным вытеснением. Такие планировщики называют ***кооперативно-вытесняющими***

### Источники:

- [Планировщик Go — самый подробный гайд простым языком](https://habr.com/ru/articles/891426/)
