# Планировщик

___Планировщик (scheduler) Go___ - это механизм `runtime`, который управляет горутинами. В статье `runtime` планировщик уже частично обсуждался, однако в этой статье он будет рассмотрен более детально.

### Планировщики ОС

Планировщик Go работает в связке с планировщиком ОС, но предоставляет более высокоуровневую абстракцию для конкурентного выполнения кода.

Для понимания работы планировщика Go потребуются два основных понятия:

1) ***Процесс*** -  выполняющаяся программа.
2) ***Поток (thread)*** - обособленная часть процесса, которая может выполняться на CPU. У каждого процесса есть один главный тред и по мере необходимости вспомогательные.

Это существенное упрощение, в Windows и Linux это все реализовано сложнее.

У компьютера есть ядра CPU, которые выполняют вычисления. В зависимости от их количества возможны два подхода:

1) ***Конкурентность (Concurrency)***
    - Если ядро одно, потоки выполняются по очереди, получая небольшие кванты времени.
    - Для пользователя это выглядит как одновременная работа, хотя на самом деле потоки быстро переключаются.
2) ***Параллелизм (Parallelism)***
    - Если ядер много, потоки могут выполняться действительно одновременно, по одному на каждое ядро.

Эти подходы сочетаются: обычно потоков больше, чем ядер, поэтому ОС комбинирует параллельное и конкурентное выполнение.

Но у потоков ОС есть недостаток: их переключение ***context switching*** требует значительных ресурсов, если же потоков будет слишком большое количество, то процессор будет только успевать между ними переключаться. Кроме того, каждый поток занимает как правило, существенное количество памяти.

В идеале, программа должна создавать как можно меньше тредов. Go решает эту проблему, вводя ***легковесные горутины***, которыми управляет его собственный планировщик.

### GMP модель

Каждый вызов функции через `go` запускает её в отдельном "потоке", что позволяет выполняться ей конкурентно с другим кодом. Тогда это выполнение этой функции будет конкурировать с выполнением "основного" кода и другими функциями, запущенными при помощи `go`.

Назовем все такие "потоки" ***горутинами*** - это легковесные аналоги потоков (threads), но управляемые рантаймом Go, а не ОС. Притом, в конечном счете горутины будут исполняться в треде.

> Еще говорят, горутины и Go-планировщик - это user space, а треды и планировщик ОС - это kernel space.

Каждая горутина может быть в одном из этих статусах:

- ***Waiting*** — не готова к запуску, так как чего-то ждёт.
- ***Runnable*** — готова к запуску, как только освободится тред.
- ***Executing*** - выполняется на каком-то треде.

У треда статусы аналогичные.

***Машина M (machine)*** будет непосредственно выполнять горутину. По сути, машиной является системный тред. ***Процессор P (processor)*** будет перекладывать горутины в машины, то есть привязывать горутину к треду.

> Процессор P - это не ядро CPU. Термины просто похожи названиями.

Машины M, процессоры P и горутины G составляют ___GMP модель___. 

### Пул тредов

По мере появления и выполнения горутин нужно создавать треды. Очевидно, что создавать каждой горутине новый тред - это плохое решение. Пусть после выполнения горутины процессор перемещает использованный тред в ***пул тредов***. 

Тогда теперь при запуске горутины:

1) Проверяем, есть ли в пуле свободный тред. Если есть, берём его для выполнения горутины.

2) Если нет, проверяем сколько сейчас задействовано тредов. Если меньше установленного лимита, то создаём новый тред и отдаём ему горутину. Когда горутина закончит работу, отправим этот тред в пул.

3) Если же количество тредов достигло лимита, горутина будет ждать пока какой-нибудь из ранее созданных не освободится, вернувшись в пул. Как освободится, передадим ему горутину в работу.

Теперь появилась очередь из ждущих горутин - ***Global Run Queue (GRQ)***. GRQ - это FIFO очередь (first in, first out), чем раньше горутина пришла, тем раньше получит тред.

Лимит тредов равен количеству доступных ядер CPU. Тредов не должно быть больше, чем ядер CPU. Теперь можно позволить к Треду приставить по отдельному Процессору. То есть, у каждого Процессора теперь будет свой собственный тред.

### Локальные очереди и Work Stealing

Введение GPQ привело к новой проблеме. Теперь при параллельном доступе нескольких процессоров к GPQ, может возникнуть ***состояние гонки (race condition)***. Для избежания этого доступ GPQ осуществляется при помощи Mutex.

Теперь проблемы с доступом к GRQ не будет, но он стал напорядок медленнее, особенно эта проблема актуальна для компьютеров с большим количеством ядер CPU.

Добавим каждому Процессору свою ***локальную очередь LRQ (local run queue)***, чтобы он брал задачи и оттуда тоже. Но как же будут попадать горутины в LRQ? Каждый раз, когда Процессор пытается взять какую-то горутину, он будет действовать по этому алгоритму:

1) 1/61 раз проверяем GRQ, и если там есть горутины, то берём оттуда.
2) Если нет, проверяем LRQ.
3) Если там нет, пытаемся украсть у другого Процессора.
4) Если не получилось, проверяем GRQ.
5) Network Poller (будет объяснено позже)

На этапе 3 происходит ***Work Stealing***. Когда Процессор простаивает, он забирает горутины из LRQ других Процессоров.

